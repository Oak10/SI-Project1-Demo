receivers:
  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/filelogreceiver/README.md
  filelog:
    include:
      - /var/lib/docker/containers/*/*-json.log
    # encoding: utf-8
    include_file_name: false
    include_file_path: true
    operators:
      - id: parser-docker
        timestamp:
          layout: "%Y-%m-%dT%H:%M:%S.%LZ"
          parse_from: attributes.time
        type: json_parser
      - id: extract_metadata_from_docker_tag
        parse_from: attributes.attrs.tag
        regex: ^(?P<name>[^\|]+)\|(?P<image_name>[^\|]+)\|(?P<id>[^$]+)$
        type: regex_parser
        if: "attributes?.attrs?.tag != nil"
      - from: attributes.name
        to: resource["docker.container.name"]
        type: move
        if: "attributes?.name != nil"
      - from: attributes.image_name
        to: resource["docker.image.name"]
        type: move
        if: "attributes?.image_name != nil"
      - from: attributes.id
        to: resource["docker.container.id"]
        type: move
        if: "attributes?.id != nil"
      - from: attributes.stream
        to: resource["log.io.stream"]
        type: move
      - field: attributes.attrs.tag
        type: remove
        if: "attributes?.attrs?.tag != nil"
      - from: attributes.log
        to: body
        type: move
    poll_interval: 200ms
    start_at: beginning

  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/hostmetricsreceiver/README.md#getting-started
  hostmetrics:
    collection_interval: 30s
    root_path: /hostfs
    scrapers:
      cpu: {}
      load: {}
      memory: {}
      disk: {}
      filesystem: {}
      network: {}

  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/dockerstatsreceiver/README.md
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    collection_interval: 30s
    timeout: 10s
    api_version: 1.45
    metrics:
      container.blockio.io_service_bytes_recursive:
        enabled: false
      container.cpu.usage.kernelmode:
        enabled: false
      container.cpu.usage.total:
        enabled: false
      container.cpu.usage.usermode:
        enabled: false
      container.cpu.utilization: # enabled by defaut (Percent of CPU used by the container)
        enabled: true
      container.memory.file: # enabled by defaut (Amount of memory used to cache filesystem data, including tmpfs and shared memory - cgroups v2)
        enabled: false
      container.memory.percent: # enabled by defaut (Percentage of memory used)
        enabled: true
      container.memory.total_cache:
        enabled: false
      container.memory.usage.limit:
        enabled: true
      container.memory.usage.total: # enabled by default. (Memory usage of the container. This excludes the cache.)
        enabled: true
      container.network.io.usage.rx_bytes: # enabled by default (Bytes received by the container.)
        enabled: true
      container.network.io.usage.rx_dropped:
        enabled: false
      container.network.io.usage.tx_bytes:
        enabled: true
      container.network.io.usage.tx_dropped:
        enabled: false
      # Optional Metrics:
      container.cpu.throttling_data.periods:
        enabled: true

processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
  signozspanmetrics/cumulative:
    metrics_exporter: clickhousemetricswrite
    metrics_flush_interval: 60s
    latency_histogram_buckets:
      [
        100us,
        1ms,
        2ms,
        6ms,
        10ms,
        50ms,
        100ms,
        250ms,
        500ms,
        1000ms,
        1400ms,
        2000ms,
        5s,
        10s,
        20s,
        40s,
        60s,
      ]
    dimensions_cache_size: 100000
    dimensions:
      - name: service.namespace
        default: default
      - name: deployment.environment
        default: default
      # This is added to ensure the uniqueness of the timeseries
      # Otherwise, identical timeseries produced by multiple replicas of
      # collectors result in incorrect APM metrics
      - name: signoz.collector.id
      - name: service.version
      - name: browser.platform
      - name: browser.mobile
      - name: k8s.cluster.name
      - name: k8s.node.name
      - name: k8s.namespace.name
      - name: host.name
      - name: host.type
      - name: container.name
  # memory_limiter:
  #   # 80% of maximum memory up to 2G
  #   limit_mib: 1500
  #   # 25% of limit up to 2G
  #   spike_limit_mib: 512
  #   check_interval: 5s
  #
  #   # 50% of the maximum memory
  #   limit_percentage: 50
  #   # 20% of max memory usage spike expected
  #   spike_limit_percentage: 20
  # queued_retry:
  #   num_workers: 4
  #   queue_size: 100
  #   retry_on_failure: true
  resourcedetection:
    # Using OTEL_RESOURCE_ATTRIBUTES envvar, env detector adds custom labels.
    detectors: [env, system] # include ec2 for AWS, gcp for GCP and azure for Azure.
    timeout: 2s
  signozspanmetrics/delta:
    metrics_exporter: clickhousemetricswrite
    metrics_flush_interval: 60s
    latency_histogram_buckets:
      [
        100us,
        1ms,
        2ms,
        6ms,
        10ms,
        50ms,
        100ms,
        250ms,
        500ms,
        1000ms,
        1400ms,
        2000ms,
        5s,
        10s,
        20s,
        40s,
        60s,
      ]
    dimensions_cache_size: 100000
    aggregation_temporality: AGGREGATION_TEMPORALITY_DELTA
    enable_exp_histogram: true
    dimensions:
      - name: service.namespace
        default: default
      - name: deployment.environment
        default: default
      # This is added to ensure the uniqueness of the timeseries
      # Otherwise, identical timeseries produced by multiple replicas of
      # collectors result in incorrect APM metrics
      - name: signoz.collector.id
      - name: service.version
      - name: browser.platform
      - name: browser.mobile
      - name: k8s.cluster.name
      - name: k8s.node.name
      - name: k8s.namespace.name
      - name: host.name
      - name: host.type
      - name: container.name

# extensions:
#   health_check:
#     endpoint: 0.0.0.0:13133
#   zpages:
#     endpoint: 0.0.0.0:55679
#   pprof:
#     endpoint: 0.0.0.0:1777

exporters:
  clickhousemetricswrite:
    endpoint: tcp://192.168.1.20:9000/signoz_metrics
    resource_to_telemetry_conversion:
      enabled: true
  clickhouselogsexporter:
    dsn: tcp://192.168.1.20:9000/signoz_logs
    docker_multi_node_cluster: ${DOCKER_MULTI_NODE_CLUSTER}
    timeout: 10s

service:
  # telemetry:  # Internal telemetry (already fetch with current configuration)
  #   metrics:
  #     address: 0.0.0.0:8888
  # extensions:
  #   - health_check #https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/healthcheckextension/README.md
  #   - zpages # https://github.com/open-telemetry/opentelemetry-collector/blob/main/extension/zpagesextension/README.md
  #   - pprof # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/pprofextension/README.md
  pipelines:
    metrics/generic:
      receivers: [hostmetrics, docker_stats]
      processors: [resourcedetection, batch]
      exporters: [clickhousemetricswrite]
    logs:
      receivers: [filelog]
      processors: [batch]
      exporters: [clickhouselogsexporter]
